{
    "Name": "SoHateful",
    "Subsets": [],
    "HF Link": "",
    "Link": "https://github.com/rafiulbiswas/hatespeech-detection",
    "License": "unknown",
    "Year": 2024,
    "Language": "ar",
    "Dialect": "mixed",
    "Domain": [
        "social media"
    ],
    "Form": "text",
    "Collection Style": [
        "crawling"
    ],
    "Description": "70,000 Arabic tweets, from which 15,965 tweets were selected and annotated, to identify hate speech patterns and train classification models",
    "Volume": 15965.0,
    "Unit": "sentences",
    "Ethical Risks": "High",
    "Provider": [
        "HBKU"
    ],
    "Derived From": [],
    "Paper Title": "So Hateful! Building a Multi-Label Hate Speech Annotated Arabic Dataset",
    "Paper Link": "https://aclanthology.org/2024.lrec-main.1308.pdf",
    "Script": "Arab",
    "Tokenized": false,
    "Host": "other",
    "Access": "Upon-Request",
    "Cost": "",
    "Test Split": false,
    "Tasks": [
        "hate speech detection"
    ],
    "Venue Title": "LREC-COLING",
    "Venue Type": "conference",
    "Venue Name": "",
    "Authors": [],
    "Affiliations": [
        "Wajdi Zaghouani",
        "Hamdy Mubarak",
        "Md. Rafiul Biswas"
    ],
    "Abstract": "Social media enables widespread propagation of hate speech targeting groups based on ethnicity, religion, or\nother characteristics. With manual content moderation being infeasible given the volume, automatic hate speech\ndetection is essential. This paper analyzes 70,000 Arabic tweets, from which 15,965 tweets were selected and\nannotated, to identify hate speech patterns and train classification models. Annotators labeled the Arabic tweets\nfor offensive content, hate speech, emotion intensity and type, effect on readers, humor, factuality, and spam. Key\nfindings reveal 15% of tweets contain offensive language while 6% have hate speech, mostly targeted towards\ngroups with common ideological or political affiliations. Annotations capture diverse emotions, and sarcasm is more\nprevalent than humor. Additionally, 10% of tweets provide verifiable factual claims, and 7% are deemed important.\nFor hate speech detection, deep learning models like AraBERT outperform classical machine learning approaches.\nBy providing insights into hate speech characteristics, this work enables improved content moderation and reduced\nexposure to online hate. The annotated dataset advances Arabic natural language processing research and resources.",
    "Added By": "Zaid Alyafeai"
}