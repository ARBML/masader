{
    "Name": "GEM",
    "Subsets": [],
    "HF Link": "https://hf.co/datasets/gem/xlsumm",
    "Link": "https://gem-benchmark.com/",
    "License": "Apache-2.0",
    "Year": 2021,
    "Language": "multilingual",
    "Dialect": "Modern Standard Arabic",
    "Domain": "wikipedia",
    "Form": "text",
    "Collection Style": "crawling",
    "Description": "benchmark environment for Natural Language Generation with a focus on its Evaluation, both through human annotations and automated Metric",
    "Volume": "29,229",
    "Unit": "documents",
    "Ethical Risks": "Low",
    "Provider": "Multiple Institutions",
    "Derived From": "MLSUM, XSUM, Wikilingua,WebNLG, CommonGen, E2E,DART, Czech Restaurant, ToTTo, wiki-Auto,TirkCorpus, ASSET, Schema-Guided Dialog",
    "Paper Title": "The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics",
    "Paper Link": "https://aclanthology.org/2021.gem-1.10.pdf",
    "Script": "Arab",
    "Tokenized": "No",
    "Host": "other",
    "Access": "Free",
    "Cost": "",
    "Test Split": "Yes",
    "Tasks": "summarization",
    "Venue Title": "GEM",
    "Citations": "27.0",
    "Venue Type": "workshop",
    "Venue Name": "Generation Evaluation and Metrics ",
    "Authors": "Sebastian Gehrmann,Tosin P. Adewumi,Karmanya Aggarwal,Pawan Sasanka Ammanamanchi,Aremu Anuoluwapo,Antoine Bosselut,Khyathi Raghavi Chandu,Miruna Adriana Clinciu,Dipanjan Das,Kaustubh D. Dhole,Wanyu Du,Esin Durmus,Ondrej Dusek,Chris C. Emezue,Varun Gangal,Cristina Garbacea,Tatsunori B. Hashimoto,Yufang Hou,Yacine Jernite,Harsh Jhamtani,Yangfeng Ji,Shailza Jolly,Mihir Kale,Dhruv Kumar,Faisal Ladhak,Aman Madaan,Mounica Maddela,Khyati Mahajan,Saad Mahamood,Bodhisattwa Prasad Majumder,Pedro Henrique Martins,Angelina McMillan-Major,Simon Mille,Emiel van Miltenburg,Moin Nadeem,Shashi Narayan,Vitaly Nikolaev,Rubungo Andre Niyongabo,Salomey Osei,Ankur P. Parikh,Laura Perez-Beltrachini,Niranjan Rao,Vikas Raunak,Juan Diego Rodr\u00edguez,Sashank Santhanam,Jo\u00e3o Sedoc,Thibault Sellam,Samira Shaikh,Anastasia Shimorina,Marco Antonio Sobrevilla Cabezudo,Hendrik Strobelt,Nishant Subramani,W. Xu,Diyi Yang,Akhila Yerukola,Jiawei Zhou",
    "Affiliations": ",,,,,EPFL,,Edinburgh Centre for Robotics,,,,Stanford University,Charles University,,Carnegie Mellon University,,,,FAIR,Carnegie Mellon University,University of Virginia,,,,,,,,,University of California San Diego,,,,Tilburg University,Massachusetts Institute of Technology;MIT,,,,,,,,,The University of Texas at Austin,,,,,,Institute of Mathematics and Computer Sciences;University of S\u00e3o Paulo;Pontifical Catholic University of Peru,,Allen Institute for AI;Masakhane,,,,",
    "Abstract": "We introduce GEM, a living benchmark for natural language Generation (NLG), its Evaluation, and Metrics. Measuring progress in NLG relies on a constantly evolving ecosystem of automated metrics, datasets, and human evaluation standards. Due to this moving target, new models often still evaluate on divergent anglo-centric corpora with well-established, but flawed, metrics. This disconnect makes it challenging to identify the limitations of current models and opportunities for progress. Addressing this limitation, GEM provides an environment in which models can easily be applied to a wide set of tasks and in which evaluation strategies can be tested. Regular updates to the benchmark will help NLG research become more multilingual and evolve the challenge alongside models. This paper serves as the description of the data for the 2021 shared task at the associated GEM Workshop.",
    "Added By": "Maraim Masoud"
}