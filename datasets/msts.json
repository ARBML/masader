{
    "Name": "MSTS",
    "Subsets": [],
    "HF Link": "https://huggingface.co/datasets/felfri/MSTS",
    "Link": "https://github.com/paul-rottger/msts-multimodal-safety",
    "License": "CC BY 4.0",
    "Year": 2025,
    "Language": "multilingual",
    "Dialect": "Modern Standard Arabic",
    "Domain": [
        "web pages"
    ],
    "Form": "text",
    "Collection Style": [
        "human annotation",
        "manual curation"
    ],
    "Description": "A multilingual multimodal safety test suite for vision-language models.",
    "Volume": 400.0,
    "Unit": "sentences",
    "Ethical Risks": "High",
    "Provider": [
        "Instituto de Telecomunica\u00e7\u00f5es"
    ],
    "Derived From": [],
    "Paper Title": "MSTS: A Multimodal Safety Test Suite for Vision-Language Models",
    "Paper Link": "https://arxiv.org/pdf/2501.10057",
    "Script": "Arab",
    "Tokenized": false,
    "Host": "GitHub",
    "Access": "Free",
    "Cost": "",
    "Test Split": false,
    "Tasks": [
        "safety evaluation"
    ],
    "Venue Title": "arXiv",
    "Venue Type": "preprint",
    "Venue Name": "arXiv",
    "Authors": [
        "Paul R\u00f6ttger",
        "Giuseppe Attanasio",
        "Felix Friedrich",
        "Janis Goldzycher",
        "Alicia Parrish",
        "Rishabh Bhardwaj",
        "Chiara Di Bonaventura",
        "Roman Eng",
        "Gaia ElKhoury Geagea",
        "Sujata Goswami",
        "Jieun Han",
        "Dirk Hovy",
        "Seogyeong Jeong",
        "Paloma Jereti\u010d",
        "Flor Miriam Plaza-del-Arco",
        "Donya Rooein",
        "Patrick Schramowski",
        "Anastassia Shaitarova",
        "Xudong Shen",
        "Richard Willats",
        "Andrea Zugarini",
        "Bertie Vidgen"
    ],
    "Affiliations": [
        "Bocconi University",
        "Instituto de Telecomunica\u00e7\u00f5es",
        "TU Darmstadt",
        "Hessian.AI",
        "University of Zurich",
        "Google DeepMind",
        "WalledAI",
        "King\u2019s College London",
        "Imperial College London",
        "Clarkson University",
        "Lawrence Berkeley National Laboratory",
        "KAIST",
        "University of Pennsylvania",
        "DFKI",
        "CERTAIN",
        "National University of Singapore",
        "Contextual AI",
        "Expert.ai"
    ],
    "Abstract": "Vision-language models (VLMs), which process image and text inputs, are increasingly integrated into chat assistants and other consumer AI applications. Without proper safeguards, however, VLMs may give harmful advice (e.g., how to self-harm) or encourage unsafe behaviours (e.g., to consume drugs). Despite these clear hazards, little work so far has evaluated VLM safety and the novel risks created by multimodal inputs. To address this gap, we introduce MSTS, a Multimodal Safety Test Suite for VLMs. MSTS comprises 400 test prompts across 40 fine-grained hazard categories. Each test prompt consists of a text and an image that only in combination reveal their full unsafe meaning. With MSTS, we find clear safety issues in several open VLMs. We also find some VLMs to be safe by accident, meaning that they are safe because they fail to understand even simple test prompts. We translate MSTS into eleven languages, showing non-English prompts to increase the rate of unsafe model responses. We also show models to be safer when tested with text only rather than multimodal prompts. Finally, we explore the automation of VLM safety assessments, finding even the best safety classifiers to be lacking.",
    "Added By": "Zaid Alyafeai"
}