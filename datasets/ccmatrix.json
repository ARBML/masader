{
    "Name": "CCMatrix",
    "Subsets": [],
    "HF Link": "https://hf.co/datasets/yhavinga/ccmatrix",
    "Link": "https://github.com/facebookresearch/LASER/tree/main/tasks/CCMatrix",
    "License": "unknown",
    "Year": 2020,
    "Language": "multilingual",
    "Dialect": "Modern Standard Arabic",
    "Domain": [
        "other"
    ],
    "Form": "text",
    "Collection Style": [
        "crawling"
    ],
    "Description": "80 languages, we were able to mine 10.8 billion parallel sentences, out of which only 2.9 billion are aligned with English",
    "Volume": 196000000.0,
    "Unit": "sentences",
    "Ethical Risks": "Low",
    "Provider": [
        "Facebook"
    ],
    "Derived From": [],
    "Paper Title": "CCMatrix: Mining Billions of High-Quality Parallel Sentences on the WEB",
    "Paper Link": "https://arxiv.org/pdf/1911.04944.pdf",
    "Script": "Arab",
    "Tokenized": false,
    "Host": "other",
    "Access": "Free",
    "Cost": "",
    "Test Split": false,
    "Tasks": [
        "machine translation"
    ],
    "Venue Title": "arXiv",
    "Venue Type": "preprint",
    "Venue Name": "",
    "Authors": [
        "Holger Schwenk",
        "Guillaume Wenzek",
        "Sergey Edunov",
        "Edouard Grave",
        "Armand Joulin"
    ],
    "Affiliations": [
        "Facebook AI"
    ],
    "Abstract": "We show that margin-based bitext mining in a\nmultilingual sentence space can be applied to\nmonolingual corpora of billions of sentences.\nWe are using ten snapshots of a curated common crawl corpus (Wenzek et al., 2019), totalling 32.7 billion unique sentences. Using\none unified approach for 38 languages, we\nwere able to mine 4.5 billions parallel sentences, out of which 661 million are aligned\nwith English. 20 language pairs have more\nthen 30 million parallel sentences, 112 more\nthen 10 million, and most more than one\nmillion, including direct alignments between\nmany European or Asian languages.\nTo evaluate the quality of the mined bitexts,\nwe train NMT systems for most of the language pairs and evaluate them on TED, WMT\nand WAT test sets. Using our mined bitexts\nonly and no human translated parallel data, we\nachieve a new state-of-the-art for a single system on the WMT\u201919 test set for translation between English and German, Russian and Chinese, as well as German/French. In particular, our English/German system outperforms\nthe best single one by close to 4 BLEU points\nand is almost on pair with best WMT\u201919 evaluation system which uses system combination and back-translation. We also achieve excellent results for distant languages pairs like\nRussian/Japanese, outperforming the best submission at the 2019 workshop on Asian Translation (WAT).",
    "Added By": "Zaid Alyafeai"
}