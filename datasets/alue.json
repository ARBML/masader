{
    "Name": "ALUE",
    "Subsets": [],
    "HF Link": "",
    "Link": "https://www.alue.org/tasks",
    "License": "unknown",
    "Year": 2021,
    "Language": "ar",
    "Dialect": "mixed",
    "Domain": [
        "other"
    ],
    "Form": "text",
    "Collection Style": [
        "other"
    ],
    "Description": "8 carefully selected and previously\r\npublished tasks",
    "Volume": 0.0,
    "Unit": "tokens",
    "Ethical Risks": "Medium",
    "Provider": [
        "Mawdoo3"
    ],
    "Derived From": [
        "OSACT4",
        "SemEval-2018",
        "IDAT",
        "XNLI MADAR",
        "NSURL-2019",
        "IDAT"
    ],
    "Paper Title": "ALUE: Arabic Language Understanding Evaluation",
    "Paper Link": "https://aclanthology.org/2021.wanlp-1.18.pdf",
    "Script": "Arab",
    "Tokenized": false,
    "Host": "other",
    "Access": "Free",
    "Cost": "",
    "Test Split": true,
    "Tasks": [
        "irony detection",
        "dialect identification",
        "semantic similarity",
        "offensive language detection",
        "emotion detection",
        "sentiment analysis",
        "entailment"
    ],
    "Venue Title": "WANLP",
    "Venue Type": "workshop",
    "Venue Name": "Arabic Natural Language Processing Workshop",
    "Authors": [
        "Haitham Seelawi",
        "Ibraheem Tuffaha",
        "Mahmoud Gzawi",
        "Wael Farhan",
        "Bashar Talafha",
        "Riham Badawi",
        "Zyad Sober",
        "Oday Al-Dweik",
        "Abed Alhakim Freihat",
        "Hussein T. Al-Natsheh"
    ],
    "Affiliations": [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        ""
    ],
    "Abstract": "The emergence of Multi-task learning (MTL)models in recent years has helped push thestate of the art in Natural Language Un-derstanding (NLU). We strongly believe thatmany NLU problems in Arabic are especiallypoised to reap the benefits of such models. Tothis end we propose the Arabic Language Un-derstanding Evaluation Benchmark (ALUE),based on 8 carefully selected and previouslypublished tasks. For five of these, we providenew privately held evaluation datasets to en-sure the fairness and validity of our benchmark.We also provide a diagnostic dataset to helpresearchers probe the inner workings of theirmodels.Our initial experiments show thatMTL models outperform their singly trainedcounterparts on most tasks. But in order to en-tice participation from the wider community,we stick to publishing singly trained baselinesonly. Nonetheless, our analysis reveals thatthere is plenty of room for improvement inArabic NLU. We hope that ALUE will playa part in helping our community realize someof these improvements. Interested researchersare invited to submit their results to our online,and publicly accessible leaderboard.",
    "Added By": "Zaid Alyafeai"
}