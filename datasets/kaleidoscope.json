{
    "Name": "Kaleidoscope",
    "Subsets": [],
    "HF Link": "https://hf.co/datasets/CohereForAI/kaleidoscope",
    "Link": "https://hf.co/datasets/CohereForAI/kaleidoscope",
    "License": "Apache-2.0",
    "Year": 2025,
    "Language": "multilingual",
    "Dialect": "Modern Standard Arabic",
    "Domain": [
        "web pages"
    ],
    "Form": "images",
    "Collection Style": [
        "human annotation",
        "manual curation"
    ],
    "Description": "Multilingual multimodal exam benchmark with 20,911 multiple-choice questions across 18 languages and 14 subjects.",
    "Volume": 382.0,
    "Unit": "sentences",
    "Ethical Risks": "Low",
    "Provider": [
        "Cohere For AI"
    ],
    "Derived From": [],
    "Paper Title": "Kaleidoscope: In-language Exams for Massively Multilingual Vision Evaluation",
    "Paper Link": "https://arxiv.org/pdf/2504.07072",
    "Script": "Arab",
    "Tokenized": false,
    "Host": "HuggingFace",
    "Access": "Free",
    "Cost": "",
    "Test Split": false,
    "Tasks": [
        "multiple choice question answering"
    ],
    "Venue Title": "arXiv",
    "Venue Type": "preprint",
    "Venue Name": "",
    "Authors": [
        "Israfel Salazar",
        "Manuel Fern\u00e1ndez Burda",
        "Shayekh Bin Islam",
        "Arshia Soltani Moakhar",
        "Shivalika Singh",
        "Fabian Farestam",
        "Angelika Romanou",
        "Danylo Boiko",
        "Dipika Khullar",
        "Mike Zhang",
        "Dominik Krzemi\u0144ski",
        "Jekaterina Novikova",
        "Lu\u00edsa Shimabucoro",
        "Joseph Marvin Imperial",
        "Rishabh Maheshwary",
        "Sharad Duwal",
        "Alfonso Amayuelas",
        "Swati Rajwal",
        "Jebish Purbey",
        "Ahmed Ruby",
        "Nicholas Popovi\u010d",
        "Marek Suppa",
        "Azmine Toushik Wasi",
        "Ram Mohan Rao Kadiyala",
        "Olga Tsymboi",
        "Maksim Kostritsya",
        "Bardia Soltani Moakhar",
        "Gabriel da Costa Merlin",
        "Ot\u00e1vio Ferracioli Coletti",
        "Maral Jabbari Shiviari",
        "MohammadAmin farahani fard",
        "Silvia Fernandez",
        "Mar\u00eda Grandury",
        "Dmitry Abulkhanov",
        "Drishti Sharma",
        "Andre Guarnier De Mitri",
        "Leticia Bossatto Marchezi",
        "Setayesh Heydari",
        "Johan Obando-Ceron",
        "Nazar Kohut",
        "Beyza Ermis",
        "Desmond Elliott",
        "Enzo Ferrante",
        "Sara Hooker",
        "Marzieh Fadaee"
    ],
    "Affiliations": [
        "Cohere For AI",
        "University of Copenhagen",
        "CONICET & Universidad de Buenos Aires",
        "Cohere For AI Community",
        "University of California, Santa Barbara",
        "Emory University",
        "M2ai.in",
        "Traversaal.ai",
        "Taras Shevchenko National University of Kyiv",
        "Aalborg University",
        "Karlsruhe Institute of Technology",
        "ScaDS.AI, TU Dresden",
        "T-Tech",
        "Lviv Polytechnic National University",
        "HSE University",
        "RAFT",
        "ETH Z\u00fcrich",
        "University of S\u00e3o Paulo",
        "National University Philippines",
        "Federal University of S\u00e3o Carlos",
        "SomosNLP",
        "Cisco",
        "Comenius University in Bratislava",
        "Mila, University of Montreal",
        "Uppsala University",
        "University of Bath",
        "Pioneer Center for AI",
        "Moscow Institute of Physics and Technology"
    ],
    "Abstract": "The evaluation of vision-language models (VLMs) has mainly relied on English-language benchmarks, leaving significant gaps in both multilingual and multicultural coverage. While multilingual benchmarks have expanded, both in size and languages, many rely on translations of English datasets, failing to capture cultural nuances. In this work, we propose Kaleidoscope, as the most comprehensive exam benchmark to date for the multilingual evaluation of vision-language models. Kaleidoscope is a large-scale, in-language multimodal benchmark designed to evaluate VLMs across diverse languages and visual inputs. Kaleidoscope covers 18 languages and 14 different subjects, amounting to a total of 20,911 multiple-choice questions. Built through an open science collaboration with a diverse group of researchers worldwide, Kaleidoscope ensures linguistic and cultural authenticity. We evaluate top-performing multilingual vision-language models and find that they perform poorly on low-resource languages and in complex multimodal scenarios. Our results highlight the need for progress on culturally inclusive multimodal evaluation frameworks.",
    "Added By": "Zaid Alyafeai"
}