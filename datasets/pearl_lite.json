{
    "Name": "PEARL-LITE",
    "Subsets": [],
    "HF Link": "https://huggingface.co/datasets/UBC-NLP/PEARL-LITE",
    "Link": "https://huggingface.co/datasets/UBC-NLP/PEARL-LITE",
    "License": "CC BY-NC-ND 4.0",
    "Year": 2025,
    "Language": "ar",
    "Dialect": "Modern Standard Arabic",
    "Domain": [
        "wikipedia",
        "LLM"
    ],
    "Form": "images",
    "Collection Style": [
        "human annotation",
        "LLM generated"
    ],
    "Description": "PEARL-LITE is a lightweight, smaller subset of the main PEARL benchmark. It is designed for users who need to perform quick evaluations or faster iteration cycles without using the full benchmark dataset. ",
    "Volume": 893.0,
    "Unit": "images",
    "Ethical Risks": "Low",
    "Provider": [
        "UBC-NLP"
    ],
    "Derived From": [
        "PEARL"
    ],
    "Paper Title": "Pearl: A Multimodal Culturally-Aware Arabic Instruction Dataset",
    "Paper Link": "https://arxiv.org/pdf/2505.21979",
    "Script": "Arab",
    "Tokenized": false,
    "Host": "HuggingFace",
    "Access": "Free",
    "Cost": "",
    "Test Split": false,
    "Tasks": [
        "question answering"
    ],
    "Venue Title": "arXiv",
    "Venue Type": "preprint",
    "Venue Name": "arXiv",
    "Authors": [
        "Fakhraddin Alwajih",
        "Samar M. Magdy",
        "Abdellah El Mekki",
        "Omer Nacar",
        "Youssef Nafea",
        "Safaa Taher Abdelfadil",
        "Abdulfattah Mohammed Yahya",
        "Hamzah Luqman",
        "Nada Almarwani",
        "Samah Aloufi",
        "Baraah Qawasmeh",
        "Houdaifa Atou",
        "Serry Sibaee",
        "Hamzah A. Alsayadi",
        "Walid Al-Dhabyani",
        "Maged S. Al-shaibani",
        "Aya El Aatar",
        "Nour Qandos",
        "Rahaf Alhamouri",
        "Samar Ahmad",
        "Mohammed Anwar Al-Ghrawi",
        "Aminetou Yacoub",
        "Ruwa Abu Hweidi",
        "Vatimetou Mohamed Lemin",
        "Reem Abdel-Salam",
        "Ahlam Bashiti",
        "Aisha Alansari",
        "Ahmed Ashraf",
        "Nora Alturayeif",
        "Alcides Alcoba Inciarte",
        "Adel Ammar",
        "Abdelrahim A. Elmadany",
        "Mohamedou Cheikh Tourad",
        "Ismail Berrada",
        "Mustafa Jarrar",
        "Shady Shehata",
        "Muhammad Abdul-Mageed"
    ],
    "Affiliations": [
        "The University of British Columbia",
        "Prince Sultan University",
        "Tuwaiq Academy",
        "KFUPM",
        "Cairo University",
        "Hadhramout University",
        "Misr University for Science & Technology",
        "Taibah University",
        "QafzaTech",
        "KAUST",
        "University of Nouakchott",
        "Imam Abdulrahman Bin Faisal University",
        "Hamad Bin Khalifa University",
        "InvertibleAI",
        "WMU",
        "IBB University",
        "Damascus University",
        "Birzeit University",
        "JUST",
        "UM6P",
        "UCA"
    ],
    "Abstract": "Mainstream large vision-language models (LVLMs) inherently encode cultural biases, highlighting the need for diverse multimodal datasets. To address this gap, we introduce PEARL, a large-scale Arabic multimodal dataset and benchmark explicitly designed for cultural understanding. Constructed through advanced agentic workflows and extensive human-in-the-loop annotations by 37 annotators from across the Arab world, PEARL comprises over 309K multimodal examples spanning ten culturally significant domains covering all Arab countries. We further provide two robust evaluation benchmarks (PEARL and PEARL-LITE) along with a specialized subset (PEARL-X) explicitly developed to assess nuanced cultural variations. Comprehensive evaluations on state-of-the-art open and proprietary LVLMs demonstrate that reasoning-centric instruction alignment substantially improves models' cultural grounding compared to conventional scaling methods. PEARL establishes a foundational resource for advancing culturally-informed multimodal modeling research. All datasets and benchmarks are publicly available.\n",
    "Added By": "Zaid Alyafeai"
}