{
    "Name": "EgyMMLU",
    "Subsets": [],
    "HF Link": "https://huggingface.co/datasets/UBC-NLP/EgyMMLU",
    "Link": "https://huggingface.co/datasets/UBC-NLP/EgyMMLU",
    "License": "MIT License",
    "Year": 2025,
    "Language": "ar",
    "Dialect": "Egypt",
    "Domain": [
        "public datasets"
    ],
    "Form": "text",
    "Collection Style": [
        "machine annotation"
    ],
    "Description": "Large-scale Egyptian and Moroccan dialectal Arabic datasets for pre-training and instruction-tuning NileChat LLM.",
    "Volume": 22027.0,
    "Unit": "sentences",
    "Ethical Risks": "Low",
    "Provider": [
        "UBC-NLP"
    ],
    "Derived From": [
        "MMLU"
    ],
    "Paper Title": "NileChat: Towards Linguistically Diverse and Culturally Aware LLMs for Local Communities",
    "Paper Link": "https://aclanthology.org/2025.emnlp-main.556.pdf",
    "Script": "Arab",
    "Tokenized": false,
    "Host": "HuggingFace",
    "Access": "Free",
    "Cost": "",
    "Test Split": true,
    "Tasks": [
        "multiple choice question answering"
    ],
    "Venue Title": "EMNLP",
    "Venue Type": "conference",
    "Venue Name": "Conference on Empirical Methods in Natural Language Processing",
    "Authors": [
        "Abdellah ElMekki",
        "Houdaifa Atou",
        "Omer Nacar",
        "Shady Shehata",
        "Muhammad Abdul-Mageed"
    ],
    "Affiliations": [
        "The University of British Columbia",
        "Mohammed VI Polytechnic University",
        "Tuwaiq Academy",
        "InvertibleAI"
    ],
    "Abstract": "Enhancing the linguistic capabilities of Large Language Models (LLMs) to include low-resource languages is a critical research area. Current research directions predominantly rely on synthetic data generated by translating English corpora, which, while demonstrating promising linguistic understanding and translation abilities, often results in models aligned with source language culture. These models frequently fail to represent the cultural heritage and values of local communities. This work proposes a methodology to create both synthetic and retrieval-based pre-training data tailored to a specific community, considering its (i) language, (ii) cultural heritage, and (iii) cultural values. We demonstrate our methodology using Egyptian and Moroccan dialects as testbeds, chosen for their linguistic and cultural richness and current underrepresentation in LLMs. As a proof-of-concept, we develop NileChat, a 3B parameter Egyptian and Moroccan Arabic LLM adapted for Egyptian and Moroccan communities, incorporating their language, cultural heritage, and values. Our results on various understanding, translation, and cultural and values alignment benchmarks show that NileChat outperforms existing Arabic-aware LLMs of similar size and performs on par with larger models. This work addresses Arabic dialect in LLMs with a focus on cultural and values alignment via controlled synthetic data generation and retrieval-augmented pre-training for Moroccan Darija and Egyptian Arabic, including Arabizi variants, advancing Arabic NLP for low-resource communities.We share our methods, data, and models with the community to promote the inclusion and coverage of more diverse communities in cultural LLM development: https://github.com/UBC-NLP/nilechat.",
    "Added By": "Zaid Alyafeai"
}