{
    "Name": "AREEj",
    "Subsets": [],
    "HF Link": "https://hf.co/datasets/dru-ac/ArSRED",
    "Link": "https://hf.co/datasets/dru-ac/ArSRED",
    "License": "CC BY-SA 4.0",
    "Year": 2024,
    "Language": "ar",
    "Dialect": "Modern Standard Arabic",
    "Domain": [
        "other"
    ],
    "Form": "text",
    "Collection Style": [
        "other"
    ],
    "Description": "This dataset was made by adding evidence annotations to the Arabic subset of SREDFM. The dataset is from the Proceedings of The Second Arabic Natural Language Processing Conference paper AREEj: Arabic Relation Extraction with Evidence. If you use the dataset or the model, please reference this work in your paper:",
    "Volume": 500000.0,
    "Unit": "sentences",
    "Ethical Risks": "Low",
    "Provider": [],
    "Derived From": [],
    "Paper Title": "AREEj: Arabic Relation Extraction with Evidence",
    "Paper Link": "https://aclanthology.org/2024.arabicnlp-1.6.pdf",
    "Script": "Arab",
    "Tokenized": false,
    "Host": "HuggingFace",
    "Access": "Free",
    "Cost": "",
    "Test Split": false,
    "Tasks": [
        "relation extraction"
    ],
    "Venue Title": "ArabicNLP",
    "Venue Type": "conference",
    "Venue Name": "Arabic Natural Language Processing Conference",
    "Authors": [],
    "Affiliations": [],
    "Abstract": "Relational entity extraction is key in building\nknowledge graphs. A relational entity has a\nsource, a tail and a type. In this paper, we\nconsider Arabic text and introduce evidence\nenrichment which intuitively informs models\nfor better predictions. Relational evidence is\nan expression in the text that explains how\nsources and targets relate. This paper augments the existing SREDFM relational extraction dataset with evidence annotation to its\n2.9-million Arabic relations. We leverage the\naugmented dataset to build AREEj, a relation extraction with evidence model from Arabic documents. The evidence augmentation\nmodel we constructed to complete the dataset\nachieved .82 F1-score (.93 precision, .73 recall). The target AREEj outperformed SOTA\nmREBEL with .72 F1-score (.78 precision, .66\nrecall).",
    "Added By": "Zaid Alyafeai"
}