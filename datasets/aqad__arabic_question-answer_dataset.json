{
    "Name": "AQAD: Arabic Question-Answer dataset",
    "Subsets": [],
    "HF Link": "https://hf.co/datasets/arbml/AQAD",
    "Link": "https://github.com/adelmeleka/AQAD",
    "License": "unknown",
    "Year": 2020,
    "Language": "ar",
    "Dialect": "Modern Standard Arabic",
    "Domain": [
        "wikipedia"
    ],
    "Form": "text",
    "Collection Style": [
        "crawling"
    ],
    "Description": "Arabic Questions & Answers dataset",
    "Volume": 17911.0,
    "Unit": "sentences",
    "Ethical Risks": "Low",
    "Provider": [
        "Alexu"
    ],
    "Derived From": [
        "QA from wikipedia (based on SQuAD 2 articles)"
    ],
    "Paper Title": "AQAD: 17,000+ Arabic Questions for Machine Comprehension of Text",
    "Paper Link": "https://www.semanticscholar.org/paper/AQAD%3A-17%2C000%2B-Arabic-Questions-for-Machine-of-Text-Atef-Mattar/d633e0f0a9fdd24c5e3e697478bcc30fc23c8cc8",
    "Script": "Arab",
    "Tokenized": false,
    "Host": "GitHub",
    "Access": "Free",
    "Cost": "",
    "Test Split": false,
    "Tasks": [
        "question answering"
    ],
    "Venue Title": "AICCSA",
    "Venue Type": "conference",
    "Venue Name": "International Conference on Computer Systems and Applications",
    "Authors": [
        "Adel Atef",
        "Bassam Mattar",
        "Sandra Sherif",
        "Eman Elrefai",
        "Marwan Torki"
    ],
    "Affiliations": [
        "",
        "",
        "",
        "",
        ""
    ],
    "Abstract": "Current Arabic Machine Reading for Question Answering datasets suffer from important shortcomings. The available datasets are either small-sized high-quality collections or large-sized low-quality datasets. To address the aforementioned problems we present our Arabic Question-Answer dataset (AQAD). AQAD is a new Arabic reading comprehension large-sized high-quality dataset consisting of 17,000+ questions and answers. To collect the AQAD dataset, we present a fully automated data collector. Our collector works on a set of Arabic Wikipedia articles for the extractive question answering task. The chosen articles match the articles used in the well-known Stanford Question Answering Dataset (SQuAD). We provide evaluation results on the AQAD dataset using two state-of-the-art models for machine-reading question answering problems. Namely, BERT and BIDAF models which result in 0.37 and 0.32 F-1 measure on AQAD dataset.",
    "Added By": ""
}