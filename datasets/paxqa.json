{
    "Name": "PAXQA",
    "Subsets": [],
    "HF Link": "https://huggingface.co/datasets/manestay/paxqa_val_test",
    "Link": "https://huggingface.co/datasets/manestay/paxqa_val_test",
    "License": "unknown",
    "Year": 2023,
    "Language": "multilingual",
    "Dialect": "Modern Standard Arabic",
    "Domain": [
        "news articles",
        "public datasets"
    ],
    "Form": "text",
    "Collection Style": [
        "machine annotation",
        "human annotation"
    ],
    "Description": "A synthetic Arabic-English cross-lingual QA dataset generated with parallel corpora and alignment-based translation.",
    "Volume": 593.0,
    "Unit": "sentences",
    "Ethical Risks": "Low",
    "Provider": [
        "University of Pennsylvania"
    ],
    "Derived From": [
        "XORQA"
    ],
    "Paper Title": "PAXQA: Generating Cross-lingual Question Answering Examples at Training Scale",
    "Paper Link": "https://arxiv.org/pdf/2304.12206",
    "Script": "Arab",
    "Tokenized": false,
    "Host": "HuggingFace",
    "Access": "Free",
    "Cost": "",
    "Test Split": true,
    "Tasks": [
        "question answering"
    ],
    "Venue Title": "arXiv",
    "Venue Type": "preprint",
    "Venue Name": "arXiv",
    "Authors": [
        "Bryan Li",
        "Chris Callison-Burch"
    ],
    "Affiliations": [
        "University of Pennsylvania"
    ],
    "Abstract": "Existing question answering (QA) systems owe much of their success to large, high-quality training data. Such annotation efforts are costly, and the difficulty compounds in the cross-lingual setting. Therefore, prior cross-lingual QA work has focused on releasing evaluation datasets, and then applying zero-shot methods as baselines. This work proposes a synthetic data generation method for cross-lingual QA which leverages indirect supervision from existing parallel corpora. Our method termed PAXQA (Projecting annotations for cross-lingual (x) QA) decomposes cross-lingual QA into two stages. First, we apply a question generation (QG) model to the English side. Second, we apply annotation projection to translate both the questions and answers. To better translate questions, we propose a novel use of lexically-constrained machine translation, in which constrained entities are extracted from the parallel bitexts.\nWe apply PAXQA to generate cross-lingual QA examples in 4 languages (662K examples total), and perform human evaluation on a subset to create validation and test splits. We then show that models fine-tuned on these datasets outperform prior synthetic data generation models over several extractive QA datasets. The largest performance gains are for directions with non-English questions and English contexts. Ablation studies show that our dataset generation method is relatively robust to noise from automatic word alignments, showing the sufficient quality of our generations. To facilitate follow-up work, we release our code and datasets at https://github.com/manestay/paxqa .",
    "Added By": "Zaid Alyafeai"
}