{
    "Name": "AQMAR",
    "Subsets": [],
    "HF Link": "https://hf.co/datasets/arbml/AQMAR",
    "Link": "https://www.cs.cmu.edu/~ark/ArabicNER/",
    "License": "CC BY-SA 3.0",
    "Year": 2012,
    "Language": "ar",
    "Dialect": "Modern Standard Arabic",
    "Domain": [
        "wikipedia"
    ],
    "Form": "text",
    "Collection Style": [
        "crawling"
    ],
    "Description": "This is a 74,000-token corpus of 28 Arabic Wikipedia articles hand-annotated for named entities.",
    "Volume": 74000.0,
    "Unit": "tokens",
    "Ethical Risks": "Low",
    "Provider": [
        "CMU"
    ],
    "Derived From": [],
    "Paper Title": "Recall-Oriented Learning of Named Entities in Arabic Wikipedia",
    "Paper Link": "https://aclanthology.org/E12-1017.pdf",
    "Script": "Arab",
    "Tokenized": false,
    "Host": "other",
    "Access": "Free",
    "Cost": "",
    "Test Split": false,
    "Tasks": [
        "named entity recognition"
    ],
    "Venue Title": "EACL",
    "Venue Type": "conference",
    "Venue Name": "European Chapter of the Association for Computational Linguistics",
    "Authors": [
        "B. Mohit",
        "Nathan Schneider",
        "Rishav Bhowmick",
        "Kemal Oflazer",
        "Noah A. Smith"
    ],
    "Affiliations": [
        "",
        "",
        "",
        "",
        ""
    ],
    "Abstract": "We consider the problem of NER in Arabic Wikipedia, a semisupervised domain adaptation setting for which we have no labeled training data in the target domain. To facilitate evaluation, we obtain annotations for articles in four topical groups, allowing annotators to identify domain-specific entity types in addition to standard categories. Standard supervised learning on newswire text leads to poor target-domain recall. We train a sequence model and show that a simple modification to the online learner---a loss function encouraging it to \"arrogantly\" favor recall over precision---substantially improves recall and F1. We then adapt our model with self-training on unlabeled target-domain data; enforcing the same recall-oriented bias in the self-training stage yields marginal gains.",
    "Added By": "Zaid Alyafeai"
}