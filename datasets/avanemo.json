{
    "Name": "AVANEmo",
    "Subsets": [],
    "HF Link": "",
    "Link": "https://www.kaggle.com/suso172/arabic-natural-audio-dataset/home",
    "License": "CC BY-NC-SA 4.0",
    "Year": 2019,
    "Language": "ar",
    "Dialect": "mixed",
    "Domain": [
        "TV channels"
    ],
    "Form": "videos",
    "Collection Style": [
        "crawling",
        "human annotation"
    ],
    "Description": "First audio-visual Arabic emotional dataset with 3000 clips covering six emotions from natural YouTube videos",
    "Volume": 3000.0,
    "Unit": "videos",
    "Ethical Risks": "Low",
    "Provider": [
        "Jordan University of Science and Technology"
    ],
    "Derived From": [],
    "Paper Title": "The Audio-Visual Arabic Dataset for Natural Emotions",
    "Paper Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8972836",
    "Script": "Arab",
    "Tokenized": false,
    "Host": "kaggle",
    "Access": "Free",
    "Cost": "",
    "Test Split": false,
    "Tasks": [
        "emotion classification"
    ],
    "Venue Title": "FiCloud",
    "Venue Type": "conference",
    "Venue Name": "International Conference on Future Internet of Things and Cloud",
    "Authors": [
        "Ftoon Abu shaqra",
        "Rehab Duwairi",
        "Mahmoud Al-Ayyoub"
    ],
    "Affiliations": [
        "Jordan University of Science and Technology"
    ],
    "Abstract": "Emotions are a crucial aspect of human life and\nthe researchers have tried to build an automatic emotion\nrecognition system that helps to provide important real-world\napplications. The psychologists have shown that emotions differ\nacross culture, considering this fact, we provide and describe the\nfirst audio-visual Arabic emotional dataset which called\n(AVANEmo). In this work we aim to fill the gap between studies\nof emotion recognition for Arabic content and other languages\nby provided an Arabic dataset which is a major and\nfundamental part of build emotion recognition application. Our\ndataset contains 3000 clips for video and audio data, and it\ncovers six basic emotional labels (Happy, Sad, Angry, Surprise,\nDisgust, Neutral). Also, we provide some baseline experiments\nto measure the primitive performance for automated audio and\nvisual emotion recognition application using the AVANEmo\ndataset. The best accuracy that we achieved was 54.5% and\n57.9% using the audio and visual data respectively. The data\nwill be available for distribution to researchers",
    "Added By": "Zaid Alyafeai"
}